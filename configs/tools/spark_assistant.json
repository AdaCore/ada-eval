{
  "timeout_s": 60,
  "threads": 4,
  "stats_file": "stats.json",
  "iteration_limit": 10,
  "llm_config": {
    "provider": "Ollama",
    "model": "llama3.1"
  }
}
